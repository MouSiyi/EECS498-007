{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "## Challenges:\n",
    "- Semantic Gap    \n",
    "What an image that the computer sees is just a big grid of numbers between [0, 255](RGB)\n",
    "How to map this grid into a semantically meaningful category label?\n",
    "- Viewpoint Variation    \n",
    "And if we change the image slightly(e.g. same individual change an angle), the grid of pixel values would change greatly.    \n",
    "How to make a robust map to deal with the changes?    \n",
    "- Intraclass Variation    \n",
    "And we also need to deal with changes within the category(different individual)     \n",
    "- Fine-Grained Categories\n",
    "- Background Clutter\n",
    "- Illumination Changes\n",
    "- Deformation\n",
    "e.g. different poses\n",
    "- Occlusion\n",
    "e.g. objects covered\n",
    "\n",
    "## Motivation: Building Block for other tasks\n",
    "Image Classification can be a block for constructing other algorithms      \n",
    "->Object Detection: One way to perform object detection is to slide windows for image classification     \n",
    "->Image Captioning: Given an image, we want to write a sentence to describe it. The task can be a sequence of classification problems      \n",
    "->..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning: Data-Driven Approach\n",
    "1. Collect a dataset of images and labels\n",
    "2. Use machine learning to train a classifier\n",
    "```python\n",
    "def train(images, labels):\n",
    "    #Machine learning\n",
    "    return model\n",
    "```\n",
    "3. Evaluate the classifier on new images\n",
    "```python\n",
    "def predict(model, test_images):\n",
    "    # Use model to predict labels\n",
    "    return test_labels\n",
    "```\n",
    "\n",
    "Different from classic programming pipeline that is driven by aquired knowledge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "- MN\n",
    "- CIFAR10\n",
    "- CIFAR100\n",
    "- ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First classifier: Nearest Neighbor\n",
    "### Simple Nearest Neighbor\n",
    "- The training function is trivial, only to memorize all the data and labels\n",
    "- The predict function takes in the image and returns the label of most similar training image\n",
    "\n",
    "Therefore we first need a distance metric to compute the semantic similarity.\n",
    "#### Distance Metric to compare images\n",
    "- L1 distance: $d_1(I_1, I_2) = \\sum_p|I_1^p-I_2^p|$\n",
    "![Alt text](image-1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NearestNeighbor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"X is N x D where each row is an example. y is 1-d of size N\"\"\"\n",
    "        self.Xtr = X\n",
    "        self.ytr = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"X is N x D where each row is an example we wish to predict label for\"\"\"\n",
    "        num_test = X.shape[0]\n",
    "        # make sure the output type matches\n",
    "        Ypred = np.zeros(num_test, dtype=self.ytr.dtype)\n",
    "\n",
    "        #loop over all test rows\n",
    "        for i in range(num_test):\n",
    "            distances = np.sum(np.abs(self.Xtr[i] - X[i]), axis=1)\n",
    "            min_index = np.argmin(distances)\n",
    "            Ypred[i] = self.ytr[min_index]\n",
    "            \n",
    "        return Ypred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawbacks using simple nearest neighbor\n",
    "- Training complexity: $O(1)$\n",
    "- Testing complexity: $O(N)$     \n",
    "We can afford slow training, but want fast testing/predicting!\n",
    "\n",
    "Using this method we can get training images that looks like the testing images, but the classfier actually does not know what it's looking for(not get the semantic meaning).\n",
    "![Alt text](image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dicision Boundaries\n",
    "Decision boundary is the boundary between 2 classification region.    \n",
    "They can be noisy and subject to outliers.   \n",
    "We want to smooth out the decision boundaries and gives more robust classification\n",
    "![Alt text](image-3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "Using more neighbors helps reduce the effect of outliers.   \n",
    "But this may also creates ties between classifications that we need to break.\n",
    "\n",
    "#### Distance Metric\n",
    "L2 distance: $d_2(I_1, I_2) = \\sqrt{\\sum_p(I_1^p-I_2^p)^2}$\n",
    "![Alt text](image-4.png)\n",
    "The semantic meaning of using L2 metric is not intuitively clear, but with L2 distance we can apply K-Nearest Neighbors to any type of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Choices about our learning algorithm that we donot learn from the training data.\n",
    "- The best value of K to use\n",
    "- The best distance metric to use\n",
    "Very problem-dependent\n",
    "#### Setting hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
